\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{titling}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{siunitx}
\usepackage{subcaption}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{float}
\usepackage{listings}
\usepackage{pdfpages}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{tabto}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\begin{document}
\begin{titlepage}
   \begin{center}
   % Centre the page to look neat
       \vspace*{2cm}
        % Set space from top
       \textbf{\LARGE Bio-Inspired Robotic Navigation On Varied Terrain}
% Name separated by break lines and supervisor name
    
       \vspace{1cm}
       % Set space from title
        \textbf{Dexter R Shepherd [candNo: 215819] \\ Supervisor: Dr James Knight}

       \vfill
       % allow it to stretch and sink verticaly
            % Smaller text with title and course name
       Final Report\\
       Computer Science and Artificial Intelligence\, BSc
            
       \vspace{0.8cm}
       % Set space from details
     % Display photo of the logo (small size)
     
       \includegraphics[width=0.2\textwidth]{University_of_Sussex_Logo.png}
       
         % Display establishment information
       Department of Informatics\\
       University of Sussex \\
       
       2021
            
   \end{center}
\end{titlepage}

\newpage 
\includegraphics[width=0.6\linewidth]{Dyslexia Sticker (2).jpg}
\\\\

        % Set space from top
       \textbf{\LARGE Statement of authenticity}
       \vspace{0.8cm}
       
       This report is submitted as part requirement for the degree of Computer Science and Artificial Intelligence (BSc) at the University of Sussex. It is the product of my own labour except where indicated in the text. The report may be freely copied and distributed provided the source is acknowledged. I hereby give permission for a copy of this report to be loaned out to students in future years
       \vspace{2cm}
       \\Signed:\\
       \vspace{0.8cm}
       \includegraphics[width=0.5\textwidth]{sig.PNG}

       Dexter R Shepherd
       
\vspace*{1cm}
        % Set space from top
       \textbf{\LARGE Acknowledgements}
       \vspace{0.8cm}
       \\
        TODO
 
         \\
\vspace*{1cm}
        % Set space from top
       \textbf{\LARGE Summary}
       \vspace{0.8cm}
       \\
       TODO
       
       \\
\newpage 
\tableofcontents
\newpage

\section{Introduction}
In this project, I have investigated autonomous robotic navigation through localized decisions based on previous experience. Nearly all organisms are limited at some point when it comes to movement. For example, an octopus can fit through an aperture that is bigger than its beak \cite{octopus} and a person can climb over rocks, but only if they have grip points for hands and feet. These environmental barriers define constraints to an organism’s ability to traverse across it. When a path looks too arduous, we will often choose a more accessible route if possible. 

These constraints also apply to robots. Consider a Mars Rover over 395 million km away from the person controlling it. If the Rover were to get stuck, there would be no one to recover it and -- as it takes 181 seconds for a signal to get from Earth to Mars -- real-time control is impossible. Therefore, a robot, like a biological organism, needs a sense of self-preservation so needs to know its limitations and not attempt tasks of movement outside these physical constraints.
\cite{reinforcementLearning} 

Our agent was set a target location and had to reach it while avoiding hazardous/overly complex terrain within the environment. Success was defined as whether the agent got there safely, and how much extra energy was consumed.
When deciding on routes, there may be the scenario that all paths are within the constraints but some are simpler to navigate than others. In this situation, the agent will need to pick the option which requires the “least” effort. The best-case scenario for the agent I am developing is governed by the level of complexity of movement necessary to overcome the obstacle. If the agent gets stuck it will get no reward, if the agent makes unnecessary movement while moving over simple terrain, it will get little reward.

I initially explored this problem using simulation before moving to a robot platform with a back actuator, stabilizer and neck actuator. The robot needed to learn to use these features to help it navigate over the landscape. This robot performed this task by using computer vision techniques, which forms a prediction on the best route to take via a movement instructions generated at each move.

\section{Professional and Ethical considerations}

In line with the BCS Code of Conduct, we must only undertake research within our competency. The Computer Vision and Acquired Intelligence; and Adaptive Behaviour modules have given me the relevant knowledge to attempt the task of terrain navigation. In addition to this, the Junior Research Associate scheme has given me a valuable background in robotics and evolving hardware. 

While no ethical approval is needed for this project, there are indisputable risks of dual use in AI research. However, at the fundamental level that I am working on, I have made a conscious decision to prioritise Open Science and all of my code will be publicly available on Github. 

Because we will train our robot on images of real world environments, we will have to consider the dangers of people being in view and thus consider the GDPR rules. However, as the resolution of images will be low, this will not be recognizable. 

Another ethical consideration is the safety involved in testing as the robot could be a trip hazard. Therefore, we will test the robot in an environment that it cannot hit people. This will be the safety netted area of the Future Technologies Lab. 

%BODY OF REPORT

\section{Requirement analysis}
Existing  robotic solutions have not combined bio-inspired chassis design with reinforcement learning. This project will use a physical robot platform and a simulation of this platform for the gathering of data.

\subsection{User Needs and ideal features}
The agent will need to learn how to recognize the differences between rough and smooth terrain based on visual information and furthermore learn how to traverse it. Ideally, the physical robot will use its back actuator to improve its ability to climb over terrain. 

The agent will need to understand its limitations and not attempt routes that it will get stuck on. Ideally this will be demonstrated on a physical robot but, if time pressure prevents this, it is still essential the algorithm works in simulation. 

\subsection{Limitations}
This project does not intend to create a robot that can climb any terrain. While the Wheg design will improve the robot's climbing ability, it will not make it impervious to the laws of physics! 

\subsection{Problem the system is solving}
The problem this research is solving is to improve autonomous robotic navigation for danger detection without the use of training data as a robot can be deployed within different environments, which makes obstacle recognition harder. 

\section{Methods}

\subsection{Simulation}
I set up a Python simulation by generating a 2D map using Perlin noise, seen in figure~\ref{fig:perlin}. Perlin noise is a type of gradient noise commonly used to procedurally generate terrain~\cite{perlin} where the value of the space between two points changes smoothly. A grid of ($n$) dimensions is created. Each index is assigned a random vector, where the dot product is calculated, which allows interpolation to generate noise.

%We present the interpolation between the dot products mathematically using $a$ to represent a grid node, with $0$ and $1$ being the grid node index. 

\begin{figure}[H]
\centering
  \includegraphics[width=0.9\linewidth]{Sim2d.png}
  \caption{2D simulation plot of a 3D terrain. Random generated points are shown to show the position of agents and rewards. }
  \label{fig:perlin}
\end{figure}
The smoothstep function represents a sigmoid-like interpolation. 
The persistence,  octaves, and lacunarity are all altered via parameters in the world creation function. The octave is generate via a combination of frequency-amplitudes. Each octave adds a layer of detail to the world, where the contribution of each octave is defined by persistence. The lucunarity defines how much detail is added or removed at each layer. This function formed a map held as a two-dimensional array representing terrain heights numerically. 

In such simulations, we can find how far a point is from the start position and the terrain steepness (gradient) at any point. The energy consumed ($E$) by a robot in a given trial is denoted by the number of steps taken ($S$) and the accumulated terrain value of each place ($P$). This terrain value is the step $S$ up, down, or across from the current height. The Manhattan distanced is used as a measure of how far the agent has travelled. This which was picked in place of the euclidean distance due to increased accuracy with high dimensionality~\cite{manhatten}.

\begin{equation}
E_{nergy} = (\mid x1 - x2 \mid  + \mid  y1 - y2 \mid ) \cdot \sum_{i=1}^{S} (P_{i})
\end{equation}

\subsubsection{Environment, model and rewards}
The environmental conditions could be changed by altering the persistence parameter. By increasing the value, the terrain would become more complex with more simulated dangers such as water. 
\begin{figure}[H]
\centering
\subfloat[ ]{%
  \includegraphics[clip,width=0.5\columnwidth]{what its seeing.png}
  }
  \subfloat[ ]{%
  \includegraphics[clip,width=0.5\columnwidth]{harderTerrain.png}
  }
\caption{ Left: Model with low persistence. Right: Model with high persistence.}
\label{fig:persist}
\end{figure}
No real challenges would exist for an agent in Figure~\ref{fig:persist}a due to the smooth terrain with a very small danger of water. An agent within Figure~\ref{fig:persist}b has several pools and large changes in climb that it would need to take into consideration. Persistence was chosen at value 0.7 for the trials. 

Vision was generated as a disparity map of changes within visual perception of the agent. The first person view was generated via taking several vectors off of agent at altered angles of 20 degrees per reading. The red lines within Figure \ref{fig:persist} show the visual perception of 100 degrees. x and y represent the current agent position, and the iteration of $x_{i}$ and $y_{i}$ represents the next coordinates at the next iteration. $\alpha$ represents the start angle that the agent is facing in. 

\begin{equation}
    x_{i}, y_{i} = x+ROUND(\left|d \cdot cos(\alpha +20i) \right|), y+ROUND(\left|d \cdot sin(\alpha +20i)\right|)
\end{equation}
The round function converts the values to integers so that the pixel coordinates can be accessed. The image is generated by going through each pixel coordinate found and comparing it to the current coordinates of the agent ($current_x, current_y$) height value. 
\begin{equation}
    Height = world_{current_x,current_y}
\end{equation}
\begin{equation}
    newPixel_{k,l} = world_{x_{i}, y_{i}} - Height + 50
\end{equation}
The generated $newPixel$ at the indices of $k,l$ will have the pixel intensity of the current position of the world at the generated line $x_i,y_i$ where $i$ is the iteration through the array. We subtract the element of initial height so that if the next position is higher, then the pixel intensity will be brighter, and if lower then the pixel intensity is lower. We then add 50 to prevent negative values for the display. 
\begin{figure}[H]
\centering
\subfloat[The Agent field of view ]{%
  \includegraphics[clip,width=0.5\columnwidth]{real2.png}
  }
  \subfloat[Agent vision visual map]{%
  \includegraphics[clip,width=0.5\columnwidth]{real1.png}
  }
\caption{How the agent views the world and an aerial view that can be displayed. The agent is looking downwards on the visual map. This is recognisable by the increased climb in the in the bottom-right corner of the map. This corresponds to the hill climb facing the agent.}
\label{fig:persist}
\end{figure}

Each trial would generate a random coordinate for the agent to start in, with the condition that this start point was not in water so that the agent would not receive 0 fitness before starting. An end goal point would be generated randomly from an array of coordinated on the circumference of a circle at a set radius. 

The agent was written as its own class, where on initialization the network structure could be determined. Weights an biases are generated when an array of Gaussian noise is entered through the $set\_genes$ method as a parameter. Using a forward function, the network generates output that is converted to a vector choice using the $argmax$ function. There are 8 directions that the agent can take, therefore the network is expected to generate the probabilities of a success of each vector. 

Architecture of the network was decided through several trials of all networks. Using a microbial algorithm with the same network for 10 trials, the results of network performance was quantified. The tests used a population of 15 and 200 generations. 

\subsubsection{Strategies}
Three genetic algorithm (GA) approaches were taken to solving this task, then an alternative rule based approach was explored to find whether GAs were over-fitting the problem. 

The first GA was a simple microbial algorithm. This generated a population of varied sizes. The optimal was found at between 10-20 genes. Two genes would be selected from the sample, trialed on three different maps with randomly generated coordinates, and then fitnesses calculated. The winner would copy over to the losing gene with a crossover between a mutation of the winning gene and the current gene. 


\begin{algorithm}
\caption{Microbial}\label{euclid}
\begin{algorithmic}
\REQUIRE $gene\_population$

\STATE $gene1 \leftarrow randomPopItem(gene\_population)$
\STATE $gene2 \leftarrow randomPopItem(gene\_population)$

\STATE $fitness1 \leftarrow runTrial(gene1)$
\STATE $fitness2 \leftarrow runTrial(gene2)$
\IF{$fitness1>fitness2$}
\STATE $gene1 \leftarrow crossover(gene2,mutate(gene1))$
\ENDIF
\IF{$fitness2>fitness1$}
\STATE $gene2 \leftarrow crossover(gene1,mutate(gene2))$
\ENDIF
\STATE $gene\_population \leftarrow gene\_population.push(gene1)$
\STATE $gene\_population \leftarrow gene\_population.push(gene2)$
\RETURN $gene\_population$
\end{algorithmic}
\end{algorithm}
\newpage 

An alternative gene was explored, inspired by groups of genes within a larger population. This was used as research showed that it outperformed microbial algorithms due to having more diversity of genes within winning groups, thus preventing convergence on sub-optimal solutions.~\cite{gaMethod} Fitness was measured by the summation of the fitnesses of all genes within a group.

\begin{equation}
   GroupFitness = \sum_{i=1}^{n}(fitness(gene_{i}))
\end{equation}

\begin{algorithm}
\caption{Group Microbial}\label{euclid}
\begin{algorithmic}
\REQUIRE $gene\_population$

\STATE $group1 \leftarrow randomPopItem(gene\_population)$
\STATE $group2 \leftarrow randomPopItem(gene\_population)$
\STATE $fitness1 \leftarrow 0$
\STATE $fitness2 \leftarrow 0$
\For{$i \gets 0$ to $LENGTH(group1)$}
   \STATE $fitness1 \leftarrow fitness1 + runTrial(group1[i])$
\STATE $fitness2 \leftarrow fitness2 + runTrial(group2[i])$
\EndFor
\IF{$fitness1>fitness2$}
\STATE $group1 \leftarrow crossover(group2,mutate(group1))$
\ENDIF
\IF{$fitness2>fitness1$}
\STATE $group2 \leftarrow crossover(group1,mutate(group2))$
\ENDIF
\STATE $gene\_population \leftarrow gene\_population.push(group1)$
\STATE $gene\_population \leftarrow gene\_population.push(group2)$
\RETURN $gene\_population$
\end{algorithmic}
\end{algorithm}


The previous strategies had few converging solutions at the end of trials. This inspired the creation of the final GA algorithm, which would perform a microbial normally for x-amount of generations, then repopulate the population with mutations of the top gene. This improved the accuracy of the agents. 

\begin{algorithm}
\caption{Choose best}\label{euclid}
\begin{algorithmic}
\REQUIRE $gene\_population,gene\_fitnesses,x$

\STATE $topGenes \leftarrow [0...LENGTH(gene\_population)]$
\STATE $marker \leftarrow 0$
\For{$i \gets 0$ to $LENGTH(gene\_population)$}
   \STATE $fitness \leftarrow gene\_fitnesses[i]$
   \STATE $placed \leftarrow False$
   \STATE $count \leftarrow 0$
   \WHILE{$count<marker$ and $NOT placed$}
        \IF{$topGenes[count]<fitness$}
        \STATE $topGenes.insert(count,gene\_population)$
        \STATE $placed \leftarrow True$
        \ENDIF
    \STATE $count \leftarrow count + 1$
    \ENDWHILE
   \IF{$NOT placed$}
        \STATE $topGenes.insert(marker,gene\_population)$
    \ENDIF 
    \STATE $marker \leftarrow marker + 1$
   
\EndFor
\STATE $fitness2 \leftarrow fitness2 + runTrial(group2[i])$

\STATE $gene\_population \leftarrow [0...LENGTH(gene\_population)]$

\For{$i \gets 0$ to $LENGTH(gene\_population)$}
    \STATE $n \leftarrow RANDOM(0,x)$
    \STATE $gene\_population[i] \leftarrow mutate(topGenes[n])$
\EndFor
\RETURN $gene\_population $
\end{algorithmic}
\end{algorithm}
\newpage 

The last approach used a rule based method. This would take into consideration the vector which takes the robot closest to the target, and avoid terrain that showed significant climb (or water). 

\subsection{Robot platform}

\subsubsection{Chassis}
The prototype version of the chassis used aluminium profiles with a lithium ion battery held in the centre under pressure. Continous rotation servos attached to the sides of the profiles. 
\begin{figure}[H]
\centering
  \includegraphics[clip,width=0.4\columnwidth]{whegv1.PNG}

\caption{Wheg robot prototype (version 1)}
\label{fig:whegv1}
\end{figure}

This robot would get stuck over obstacles where the weight could not be redistributed. A bendable back actuator was implemented to the chassis to improve this, in addition suspension to absorb shock and prevent tilt of the chassis over rocks, which has become a problem for version 1. 
\begin{figure}[H]
\centering
  \includegraphics[clip,width=0.4\columnwidth]{DSC_0298 (2).JPG}

\caption{Wheg robot version 2 introduction of back actuators and suspension.}
\label{fig:whegv2}
\end{figure}

The chassis was built using aluminium servo parts, typically used for biped robots and robotic arms. This was used due to easily fitting standard servos, which made it compatible with the continuous rotation servos used for the robot's locomotion. In addition, it made it simpler to fit suspension and the cockroach inspired back. Figure~\ref{fig:whegv2} shows the robot within outdoor trials. 

The robot chassis incorporated a wheg design. This design was able to climb over terrain while maintaining stability under initial tests with an Xbox controller. The main chassis of the robot used the suspension system shown in Figure~\ref{fig:suspension} so that a higher incline on one extremity does not tilt the overall robot. This design was inspired by a Tamiya radio controlled car~\cite{tamiya}. 

\begin{figure}[H]
\centering
\subfloat[Neutral position]{%
  \includegraphics[clip,width=0.3\columnwidth]{sus1.PNG}%
}
\subfloat[Activated position]{%
  \includegraphics[clip,width=0.3\columnwidth]{sus2.PNG}%
}
\caption{Figure showing the movement of the suspension system design moving over hardware. This uses a single spring shock absorber per Wheg.}
\label{fig:suspension}
\end{figure}

The Wheg design would get caught while reversing as the claws were only grabbing one way. The robot also struggled to turn left and right on the spot. The addition of a tilting mechanisms for left and right turns was added to solve this. 

When the robot would try climb, it would within some trials need an element of height to get over obstacles. This was achieved by adding a stabiliser servo with a wheel caster on the bottom. When deployed, the wheel caster allowed the robot to carry on moving without getting caught. The heavy battery was placed at the back of the robot as it was discovered that the front needed to be lighter than the back to have improved climb. 

\begin{figure}[H]
\centering
  \includegraphics[clip,width=0.5\columnwidth]{DSC_0336.JPG}

\caption{Wheg robot version 3 with improved weight distribution, stabiliser and better whegs.}
\label{fig:whegv3}
\end{figure}

The neck used a pan and tilt mechanism was placed at the front of the robot chassis and panned left to right, to improve turning left and right within an environment. The tilt will be up and down on the axis of gravity acting as a back. A bend in the back will redistribute weight -- the exact process applied in the cockroach research~\cite{cockroach}. 

For control, the chassis used a Raspberry Pi for its low energy consumption yet reasonable processing power. It was also setup with Linux which allowed SSH control of the robot and ease of gathering results from trials. 

\subsubsection{Vision}

\section{Testing and results}


\section{Conclusions}

\bibliographystyle{unsrt}
\bibliography{sample}

\section{Appendices}
\end{document}
