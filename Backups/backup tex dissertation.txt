\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{titling}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{siunitx}
\usepackage{subcaption}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{float}
\usepackage{listings}
\usepackage{pdfpages}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\begin{document}
\begin{titlepage}
   \begin{center}
   % Centre the page to look neat
       \vspace*{2cm}
        % Set space from top
       \textbf{\LARGE Bio-Inspired Robotic Navigation On Varied Terrain}
% Name separated by break lines and supervisor name
    
       \vspace{1cm}
       % Set space from title
        \textbf{Dexter R Shepherd [candNo: 215819] \\ Supervisor: Dr James Knight}

       \vfill
       % allow it to stretch and sink verticaly
            % Smaller text with title and course name
       Interim report\\
       Computer Science and Artificial Intelligence\, BSc
            
       \vspace{0.8cm}
       % Set space from details
     % Display photo of the logo (small size)
     
       \includegraphics[width=0.2\textwidth]{University_of_Sussex_Logo.png}
       
         % Display establishment information
       Department of Informatics\\
       University of Sussex \\
       
       2021
            
   \end{center}
\end{titlepage}

\newpage 
\tableofcontents
\newpage

\section{Introduction}

In this project, I am going to investigate autonomous robotic navigation through localized decisions based on previous experience. Nearly all organisms are limited at some point when it comes to movement. For example, an octopus can fit through an aperture that is bigger than its beak \cite{octopus} and a person can climb over rocks, but only if they have grip points for hands and feet. These environmental barriers define constraints to an organism’s ability to traverse across it. When a path looks too arduous, we will often choose a more accessible route if possible. 

These constraints also apply to robots. Consider a Mars Rover over 395 million km away from the person controlling it. If the Rover were to get stuck, there would be no one to recover it and -- as it takes 181 seconds for a signal to get from Earth to Mars -- real-time control is impossible. Therefore, a robot, like a biological organism, needs a sense of self-preservation so needs to know its limitations and not attempt tasks of movement outside these physical constraints.
\cite{reinforcementLearning} 

Our agent will be set a target location and will need to reach it while avoiding hazardous/overly complex terrain within the environment. Success will be defined as whether the agent got there safely, and how much extra energy was consumed.
When deciding on routes, there may be the scenario that all paths are within the constraints but some are simpler to navigate than others. In this situation, the agent will need to pick the option which requires the “least” effort. The best-case scenario for the agent I am developing is governed by the level of complexity of movement necessary to overcome the obstacle. If the agent gets stuck it will get no reward, if the agent makes unnecessary movement while moving over simple terrain, it will get little reward.

I will initially explore this problem using simulation before moving to a robot platform with a back actuator, stabilizer and neck actuator. The robot will need to learn to use these features to help it navigate over the landscape. This robot will perform this task by using computer vision techniques, which forms a prediction on the best route to take via a movement instructions generated at each move.

\section{Professional and Ethical considerations}

In line with the BCS Code of Conduct, we must only undertake research within our competency. The Computer Vision and Acquired Intelligence; and Adaptive Behaviour modules have given me the relevant knowledge to attempt the task of terrain navigation. In addition to this, the Junior Research Associate scheme has given me a valuable background in robotics and evolving hardware. 

While no ethical approval is needed for this project, there are indisputable risks of dual use in AI research. However, at the fundamental level that I am working on, I have made a conscious decision to prioritise Open Science and all of my code will be publicly available on Github. 

Because we will train our robot on images of real world environments, we will have to consider the dangers of people being in view and thus consider the GDPR rules. However, as the resolution of images will be low, this will not be recognizable. 

Another ethical consideration is the safety involved in testing as the robot could be a trip hazard. Therefore, we will test the robot in an environment that it cannot hit people. This will be the safety netted area of the Future Technologies Lab. 


\section{Background Literature}
\subsection{Robot Locomotion}

A standard wheel has low energy consumption due to a single axis continuous rotation; however, it is limited when climbing over rough terrain. 
To improve their ability to traverse such terrain, agents can use legs for example in a hexapod configuration which is incredibly stable~\cite{gait}. However, robotic legs use multiple servos which have a high current draw and, due to the need for inverse kinematics~\cite{kinematics}, require complex control algorithms. 

The Wheg design is a wheel-leg hybrid that can traverse more challenging terrain than standard wheels while maintaining low energy consumption~\cite{moonrover}. Figure~\ref{figure : robot} shows a robot featuring Whegs with claw-like spokes which dig into rocks and obstacles. 

\begin{figure}[H]
\centering
  \includegraphics[width=0.4\linewidth]{whegv1.PNG}
  \caption{Prototype of the Wheg robot to test out the wheg design, in addition the hardware required. This prototype ran on a Raspberry Pi zero and used a phone charger cell providing 5.1V and a maximum of 2A of current.}
  \label{figure :robot_wheg_prototype}
\end{figure}

Whegs are easily manufactured via 3D printing, and there are multiple design variations of the Wheg which suit different purposes~\cite{whegDesign}. 

The European Space Agency~(ESA) adopted a similar design for the PROLERO project ~\cite{esa}. Although not quite a Wheg, it operates on a similar principle. This project used a simpler design of actuation where the legs were rods rotating on one axis. This design could at maximum travel over obstacles less than or equal to a height of \SI{10}{\centi\metre}. The total payload mass was \SI{1.5}{\kilo\gram} making it light for space travel and the rover passed the tests at the ESA planetary utilisation facility, confirming the model's validity~\cite{esa}.
\begin{figure}[H]
\centering
  \includegraphics[width=0.4\linewidth]{prolero.png}
  \caption{Figure showing the PROLERO robot taken from ESA \cite{esa} }
  \label{figure : robot_for_esa_testing_Wheg_complexions}
\end{figure}

Other potential designs are caterpillar tracks which have good energy efficiency due to the optimized traction system which allows more grip over uneven terrain. They do, however, weigh more and are more difficult to repair meaning that the robot would be inoperable if a link breakage, whereas, with wheels or Whegs, it could continue to move with worn-down tyres or grippers. 
\subsection{Biology and Bio-inspired Robotics}
Research on cockroaches explored the use of cockroach-inspired limbs and movement. This involved a bend in the back in increasing climb over obstacles. Another biological advantage was how the cockroach would run into a wall. The cockroach limbs would be brought into phase at the point of climb. The rotational locomotion of the legs is comparable to the cyclic locomotion of wheel. This robot used a Wheg design to improve its advancement in a similar locomotion. A bend in the robot created a higher stance to climb.~\cite{cockroach} 

\begin{figure}[H]
\centering
  \includegraphics[width=0.7\linewidth]{cock.png}
  \caption{Figure taken from showing the cockroach rotation to an obstacle. This is compared to a bio-inspired robot. \cite{cockroach}}
  \label{figure :cockroach}
\end{figure}

%A study on rats showed that rats would be fearful of new items in their surroundings. These changes would include mouse traps, which makes them more difficult to catch than mice. \cite{rats} This suggests there is a form of memory that stores how a common routes should look and spots an unexpected difference. 

%A similar result was found in insects where ants would learn a specific route and when a trap was placed, the ants would learn to circumnavigate. \cite{ants} Unlike the rats, avoiding traps was done through a series of trials.   

%\begin{figure}[H]
%\centering
%  \includegraphics[width=0.7\linewidth]{antPaths.PNG}
%  \caption{Figure taken from ‘Rapid Aversive and Memory Trace Learning duringRoute Navigation in Desert Ants’ With routes taken by ants broken down species of ant. Blue paths show the ants who get stuck in the trap, green paths show ants who successfully navigated through. }
%  \label{figure : robot}
%\end{figure}

%These measures in nature can inspire our own approach to navigation and hardware decisions. The cockroach is the product of millions of years of evolution, and known for being durable. These methods can inspire our own design for a robotic chassis that can also be durable in hostile environments. 

\subsection{Reinforcement Learning}
Reinforcement learning is a machine learning approach that does not need labelled training data. The focus is on exploring solutions and exploiting current knowledge through actions to maximize cumulative reward~\cite{classicalRL}.





This approach has been deployed for route planning robots to plot a solution on different terrain. The reinforcement learning approach was successful in a small number of trials. This method used a neural network that took state information to predict the next step. The research was carried out in simulation rather than a physical agent.\cite{reinforcementLearning} 

\begin{figure}[H]
\centering
  \includegraphics[width=0.5\linewidth]{RFdiag.PNG}
  \caption{Reinforcement learning simplified showing. }
  \label{figure :reinforce}
\end{figure}

Reinforcement learning is often described in terms of an agent, environment, state, reward, and action. The agent is the entity to which the reinforcement learning applies, such as a robot. The environment is the area in which the agent will roam and the state presents the agent's current position within the environment. The desired agent behaviour is then rewarded at the end of each trial. Figure~\ref{figure :reinforce} shows the process of state transition through action and reward.

This approach can include a neural network that trains under a series of trials. 

\subsubsection{Markov decision process}
The Markov decision process formulates reinforcement learning mathematically.
The model states that the future is independent of the past given the present. This is denoted mathematically by using P[t] to represent the current state of the agent, therefore P[t+1] represents the next state \cite{RFL}. 
\begin{equation}
 P[S_{t+1} \mid S_{t}] = P[S_{t+1} \mid S_{1}, ... , S_{t}]
\end{equation}
State transition probability is given by the following equation:
\begin{equation}
 P_{ss{}'} = \mathbb{P}[S_{t+1}=s{}' \mid S_{t}=s]
\end{equation}
 The agent transitions from one state to another. 
This is important to reinforcement learning as it allows values to be functions of the current state. The state representation must be informative for an effective reinforcement learning approach to take place. Manually determining optimal state space is challenging, therefore the use of neural networks can be used.

Our agent will use this principle to apply the reinforcement learning. The state of the environment is taken and changed by the action produced. The agent will now have a new state. 

\subsection{Genetic algorithms}
Genetic algorithms are optimization methods which are inspired off of biological systems such as evolution~\cite{genetic}. Over a number of generations encoded information~($genotype$) will be changed~($mutated$
), where this change is measured via a fitness function. If the mutation has helped the overall goal then it will get a high fitness and replace other genotypes within the population.

An approach to evolutionary strategies is to generate the weights and biases via a Gaussian distribution within a one-dimensional array. Each generation will allow mutation of these values. Mutation functions fit Gaussian noise on top of the current encoded data, which alters the operation of the neural network when applied.

One optimization approach uses a Microbial algorithm that generates a population of Gaussian distributions and trials each of them in a tournament against one another. The winner overwrites the loser~ \cite{microbial}. Particle Swarm optimization uses a method inspired by particle physics. When particles are energized through heat and cooled slowly, they move back into place better than if called quickly. This theory applied as a genetic algorithm allows sub-optimal solutions to move away and trial new solutions~\cite{particle}.

The optimization of the agent can be achieved by implementing evolutionary strategies to guide training towards a solution. 

\subsection{Evaluating performance of robots on terrain}
It is important to be able quantify an agents' performance across trials.
Current research in rough terrain robotics has used physical attributes such as the coefficient of friction and slippage plotted against the climb~\cite{measure}.

\begin{figure}[H]
\centering
  \includegraphics[width=0.5\linewidth]{roverGyro.PNG}
  \caption{Figure Taken from a 3D plot of the simulated paths for a moon rover \cite{reinforcementLearning} The z-axis shows a prominent climb on map 1 and map 3.}
  \label{figure :robot_climbing}
\end{figure}

Studies~\cite{chassisTerrain} have measured Locomotion performance based on several values, including slippage, required torque, and minimum friction coefficient. These metrics create an overall score, plotted throughout each trial. $\mu$ represents the friction coefficient needed for tangential ($R$) and normal ($N$) force with ($r$) given by the radius of the wheel with torque ($T$).
\begin{equation}
\mu _{needed} = \frac{R}{N}=\frac{T\cdot r}{N}
\end{equation}

Slippage consumes energy without making the robot move forward. Slippage was calculated using the encoders on wheels. Distance is calculated using the following equation which uses encoder values. The wheel encoder ($\Delta _{coder}$) is used and multiplied by the circumference of the wheel ($2 \cdot \pi \cdot r$). This divides over the pulse/turn multiplied by the gear ratio.
\begin{equation}
\text{Distance} = \frac{\Delta _{coder}\cdot 2 \cdot \pi \cdot r}{N_{pulse}\cdot R_{gearbox}} 
\end{equation}
The slippage is the difference of ground truth and wheel odometry~\cite{chassisTerrain}.
These factors form a Max and Min G score. Both robot robots could provide enough torque, but that does not mean equal performance. The G score is taken from all the G values, calculated from the torque needed. These attributes are easily calculated in simulation but would be harder to find on a physical robot. The use of gyroscopes and accelerometers are potentials for a substitute. There is also access to Vicon tracking which would allow 3D generation of the robot. This would allow us to quantify these attributes. 

\subsection{Sensors}
Terrain mapping sensing can take many forms. One study used a lidar sensor that would read at four layers to construct a world model. This model creates a 3D perception allowing a hexapod robot to predict movement \cite{laser}. 

Optical flow uses the vectors between pixels in two images taken one immediately after another. This can be used for optical flow alone \cite{optical}. Optical flow can also be used to calculate obstacles and swerve an agent away from the obstruction via depth estimation maps \cite{opticalDepth}. This same depth estimation method was achieved using a convolutional neural network and the Canny edge detector and morphological operators \cite{canny}. 

Depth perception via stereo imaging is another method that requires less training. A hexapod robot used this method with six legs to predict stable movement over uneven terrain. This prediction method was accurate \cite{stereo}.

\begin{figure}[H]
\centering
  \includegraphics[width=0.5\linewidth]{hexapodStereo.PNG}
  \caption{Figure showing Weaver the stereo vision hexapod. The ground is uneven for all legs, therefore the agent must adapt across all legs. }
  \label{figure :hexapod}
\end{figure}
\subsection{Contributions to the field}
Self preserving robotics are important for remote locations such as planetary exploration, or hazardous locations on earth like nuclear reactors. The preserving of autonomous robotics will save money as well as prolong the lifespan of the agent~\cite{selfpres}. Our approach will be using computer vision techniques to evaluate terrain and make safer and easier path decisions. Our design will also be implemented on a cheaper design chassis, aiming to bring down the overall cost of robot development.


\section{Requirement analysis}
Existing  robotic solutions have not combined bio-inspired chassis design with reinforcement learning. This project will use a physical robot platform and a simulation of this platform for the gathering of data.

\subsection{User Needs and ideal features}
The agent will need to learn how to recognize the differences between rough and smooth terrain based on visual information and furthermore learn how to traverse it. Ideally, the physical robot will use its back actuator to improve its ability to climb over terrain. 

The agent will need to understand its limitations and not attempt routes that it will get stuck on. Ideally this will be demonstrated on a physical robot but, if time pressure prevents this, it is still essential the algorithm works in simulation. 

\subsection{Limitations}
This project does not intend to create a robot that can climb any terrain. While the Wheg design will improve the robot's climbing ability, it will not make it impervious to the laws of physics! 

\subsection{System overview}
\subsubsection{Simulation and application of the Robot}
The agent will be evaluated in an environment, where we give it a target location and it must avoid rough terrain to get there. These constraints will be applied by calculating energy consumption. Within an environment there can be dangers, which we will simulate using sea and snow (suggesting the ground is too high) -- entering these regions will result in 0 fitness. Using a neural network with a visual representation and vector as an input layer. The output will be a left, right, forward command. When we deploy this on the robot, we will most likely use a depth camera. 

\subsubsection{Robot platform}
The robot chassis will incorporate a wheg design. This design will need to be able to climb over terrain while maintaining stability. The Whegs will be 3D printed, so must have a diameter smaller than \SI{200}{\milli\metre} due to the printer capacity. Current designs typically use claw-like hooks on the whegs. This design is limited on specific terrains due to it not being able to reverse. 

The main chassis of the robot will use the suspension system shown in figure~\ref{fig:suspension} so that a higher incline on one extremity does not tilt the overall robot. This design was inspired by a Tamiya radio controlled car~\cite{tamiya}.


\begin{figure}[H]
\centering
\subfloat[Neutral position]{%
  \includegraphics[clip,width=0.3\columnwidth]{sus1.PNG}%
}
\subfloat[Activated position]{%
  \includegraphics[clip,width=0.3\columnwidth]{sus2.PNG}%
}
\caption{Figure showing the movement of the suspension system design moving over hardware. This uses a single spring shock absorber per Wheg.}
\label{fig:suspension}
\end{figure}

In terms of back and neck actuation, we will need a pan and tilt style mechanism where the front of the robot chassis will pan left to right, to improve turning left and right within an evironment. The tilt will be up and down on the axis of gravity acting as a back. A bend in the back will redistribute weight -- the exact process applied in the cockroach research~\cite{cockroach}. 

\subsection{Programming languages}
There are numerous programming languages which could be used for the simulation and robot components of this project. Ideally, the language I use will be is suitable for both. 

Languages that are particularly well-suited to working with hardware include C++ and Python.

Arduinos use a version of C++. This can be quickly booted up and execute code sooner due to storing it in binary format. This method is more complicated for computer vision and machine learning tasks than simpler languages such as Python. 

Python is a high-level language that abstracts away from syntactic detail compared to other languages. This design makes it slower at execution but has a wide ecosystem of machine learning tools. These tools are written in C++ as Python is slow, however, Python can combine them without a significant loss of time.

When Python deploys on hardware, there are different methods to undertake. One of which is circuit Python as a Micro-controller, where a small Micro-controller compiles to work as an Arduino but using Python. This is found on the Raspberry Pi Pico, Adafruit feather and Microbit. This approach overcomes speed and complexity issues; however, these boards typically have a low amount of memory. On the higher end is the Jetson, a Nvidia-developed board design for machine learning tasks. These are heavily used within brains on boards projects. 

In this project I will use a Raspberry Pi. These are low-cost computers which have hardware access through GPIO pinouts and that run a Linux-based operating system. Linux is a good platform to do machine learning as there is plenty of library support. These are typically more expensive than Arduinos, but still much cheaper compared to higher specification models such as the Jetson. Though slower at booting than the other micro-controllers listed, it will provide the machine learning tools required for the project.


\section{Project Plan}

\begin{figure}[H]
\centering
  \includegraphics[width=0.8\linewidth]{plan.PNG}
  \caption{Timetable of development displayed as a Gantt chart }
  \label{figure :gantt}
\end{figure}

\subsection{Phase one simulation}

Phase one will focus on developing the navigation methods and a virtual environment to test within. This phase is critical for the project as simulation can test concepts more quickly and cheaply than physical robot testing. 
We will use the Python noise generation library to develop a 3D map of the terrain. 



\subsection{Phase two simulation trials}
The deployment of the simulation will test the theory of using vision to exploit navigation over rough terrain. The agent will need to pick the most accessible routes which minimize the overall energy consumption. There are multiple ways of testing this concept.

\subsection{Phase three building of physical robot}
To understand whether or not this concept works in practice, we must try it on a physical robot. The real world has many more variables which affect the performance of algorithms. Lighting, colour, and shade can have significant effects on the way the robot perceives the environment. 
We will build the robot chassis from lightweight aluminum servo apparatus, and 3D printed Whegs. 
It is essential that this design can successfully climb over terrain and can travel in both directions. We will test this using a simple remote control. Once we know the physical limitations, it can help us design the testing environment. 

\subsection{Phase four applying simulation on the physical robot}

The working reinforcement learning algorithm will deploy on the physical robot. This will test whether we can cross the ``reality gap'' and determine whether the algorithm functions with the real-life background noise. 

\subsection{Phase five evolving back movement}
Evolving back movements is not an essential feature of this project but, it will significantly improve the agent's ability to climb. If there is time, this will be trialed using a reinforcement learning approach to help redistribute weight, thus improving the climb. 

\section{Methods and Preliminary Results}

\subsection{Simulation}

We set up a Python simulation by generating a 2D map using Perlin noise, seen in figure ~\ref{fig:perlin}. Perlin noise is a type of gradient noise commonly used to procedurally generate terrain~\cite{perlin} where the value of the space between two points changes smoothly. A grid of ($n$) dimensions is created. Each index is assigned a random vector, where the dot product is calculated, which allows interpolation to generate noise.

%We present the interpolation between the dot products mathematically using $a$ to represent a grid node, with $0$ and $1$ being the grid node index. 

\begin{figure}[H]
\centering
  \includegraphics[width=0.9\linewidth]{Sim2d.png}
  \caption{2D simulation plot of a 3D terrain. Random generated points are shown to show the position of agents and rewards. }
  \label{fig:perlin}
\end{figure}
The smoothstep function represents a sigmoid-like interpolation. 
The persistence,  octaves, and lacunarity are all altered via parameters in the world creation function. The octave is generate via a combination of frequency-amplitudes. Each octave adds a layer of detail to the world, where the contribution of each octave is defined by persistence. The lucunarity defines how much detail is added or removed at each layer. This function formed a map held as a two-dimensional array representing terrain heights numerically. 



In such simulations, we can find how far a point is from the start position and the terrain steepness (gradient) at any point. The energy consumed ($E$) by a robot in a given trial is denoted by the number of steps taken ($S$) and the accumulated terrain value of each place ($P$). This terrain value is the step $S$ up, down, or across from the current height. The Manhattan distanced is used as a measure of how far the agent has travelled. This which was picked in place of the euclidean distance due to increased accuracy with high dimensionality~\cite{manhatten}.

\begin{equation}
E_{nergy} = (\mid x1 - x2 \mid  + \mid  y1 - y2 \mid ) \cdot \sum_{i=1}^{S} (P_{i})
\end{equation}


\subsection{Robotic hardware}

Throughout the initial testing, I developed three Wheg designs and evaluated two of these on a physical robot. In the first Wheg design shown in figure~\ref{fig:wheg_design_1}, each spoke had a single claw which would power more climb. 

\begin{figure}[H]
\centering
  \includegraphics[width=0.5\linewidth]{wheg.PNG}
  \caption{Initial claw design with 4 claws for stable rotation. }
  \label{fig:wheg_design_1}
\end{figure}

However, this design would struggle to reverse so I, instead, developed the reversible claw design shown in figure~\ref{fig:wheg_design_2}. 

\begin{figure}[H]
\centering
  \includegraphics[width=0.5\linewidth]{whegTri.PNG}
  \caption{Reversible claw design using a tri-claw system for strength. The 4 claw stable rotation was replaced as this design had less gaps thus making it naturally more stable.}
  \label{fig:wheg_design_2}
\end{figure}

The hardware will use light Aluminium servo parts which are typically used in biped robotics and can be purchased cheaply on the internet. The design will allow rotation servos as the back and neck, alongside continuous rotation servos for the Whegs. 


\section{Supervisor meetings}
\subsection{13/10/21}
Discussion on subsections missing from our initial draft, areas of research we should investigate and how to improve the simulation method.
We need to research more about bio-inspired robots like what we are designing and show more figures in general to the papers we have referenced and reviewed. 

\subsection{27/10/21}
We discussed how we will test the agent. Two main methods came up which was finding the highest point and making the most energy efficient path there or being set a vector and moving to it while avoiding obstacles. We looked at a paper on ants and trap avoiding which tied into our bio inspired research. Changes were suggested and made in the report. 
A discussion on sensors on the physical robot and what will work the best happened. 
\subsection{10/11/21}
Discussion over Max G score and how it ties in with the calculation of terrain. Further discussing Perlin noise and how best display my simulation work within the report. 
We then spoke about the next stage which was to get the simulation agent working.

\section{Appendices}


\setlength{\voffset}{0cm}
\setlength{\hoffset}{0cm}

\includepdf[pages=-]{Dissertation_proposal.pdf}

\setlength{\voffset}{-2.54cm}
\setlength{\hoffset}{-2.54cm}

\setlength{\voffset}{0cm}
\setlength{\hoffset}{0cm}

\begin{lstlisting}[language=Python, caption=Simulation noise generation code]
#noise generator for simulation plot
import noise
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import axes3d
import random as rnd
import copy
from matplotlib.collections import EllipseCollection

SIZE=50
def generateWorld():
    shape = (SIZE,SIZE)
    scale = 100.0
    octaves = rnd.randint(2,20)
    persistence = 0.5
    lacunarity = 2

    world = np.zeros(shape)
    for i in range(shape[0]):
        for j in range(shape[1]):
            world[i][j] = noise.pnoise2(i/scale, 
                                        j/scale, 
                                        octaves=octaves, 
                                        persistence=persistence, 
                                        lacunarity=lacunarity, 
                                        repeatx=1024, 
                                        repeaty=1024, 
                                        base=42)
    world=world*100 #normalize numbers
    world=world.astype(int)
    print("Octaves:",octaves)
    return world,shape



def pickPosition(terrain,value,deny=[],LBounds=8,UBounds=4):
    current=-100
    cords=[0,0]
    deny.append(cords)
    while cords in deny:
        while current<value-LBounds or current>value+UBounds:
            cords=[rnd.randint(0,SIZE-1),rnd.randint(0,SIZE-1)]
            current=terrain[cords[0],cords[1]]
    return cords


#canReach will make sure the problem is solvable
def canReach(terrain,start,goal,endmarked=[[False for i in range(SIZE)] for j in range(SIZE)]):
    #check whether the bot can reach the other
    #expand out from end and make paths
    y,x=start[0],start[1]
    val=False
    if terrain[x][y]!=-1 and not endmarked[x][y]:
        endmarked[x][y]=True
        if x-1>=0:
            val=canReach(terrain,[x-1,y],goal,endmarked=endmarked)
        if x+1<SIZE:
            val=canReach(terrain,[x+1,y],goal,endmarked=endmarked)
        if y-1>0:
            val=canReach(terrain,[x,y-1],goal,endmarked=endmarked)
        if y+1<SIZE:
            val=canReach(terrain,[x,y+1],goal,endmarked=endmarked)
    if x==goal[1] and y==goal[0]:
        val=True
    return val
    
    

#getBestRoute will be used to measure how fit an evolved route is
def getBestRoute(terrain,start,end):
    #find the least cost route from A to B
    #return metrics
    
    return []
def expand(terrain,Map,start):
    for i in range(len(terrain)):
        for j in range(len(terrain[i])):
            if terrain[i][j]<-5:
                Map[i][j]=-1
            elif [j,i]==start:
                Map[i][j]=0
            else:
                Map[i][j]=terrain[i][j]+getDist([j,i],start)
    return Map

def getDist(start,end):
    d1=((start[0]-end[0])**2 + (start[1]-end[1])**2)**0.5
    return int(d1)

def readIm(r=5):
    #read the ground around the agent at a radius of i
    pass



while True:
    #generate the world terrain
    world,shape=generateWorld() 
    #randomly pick a start position
    startPos=pickPosition(world,4,LBounds=6)
    vectors=[(1,1),(1,0),(0,1),(-1,-1),(-1,0),(0,-1),(-1,1),(1,-1)] #possible moves
    
    #print(canReach(Rmap,startPos,endPos))
    im = plt.imshow(world,cmap='terrain')
    cb = plt.colorbar(im)
    plt.setp(cb.ax.get_yticklabels([-1,0,1]), visible=False)
    
    plt.show()
    """
    lin_x = np.linspace(0,1,shape[0],endpoint=False)
    lin_y = np.linspace(0,1,shape[1],endpoint=False)
    x,y = np.meshgrid(lin_x,lin_y)
    fig = plt.figure()
    ax = fig.add_subplot(111, projection="3d")
    ax.plot_surface(x,y,world,cmap='terrain')


    plt.show()
    #"""

"""
    maxPath=30
    pathx=[]
    pathy=[]
    current=startPos.copy()
    energy=0
    last=startPos.copy()
    for i in range(maxPath):
        v=rnd.choice(vectors)
        pathx.append(current[0]+v[0])
        pathy.append(current[1]+v[1])
        last=current.copy()
        current[0]+=v[0]
        current[1]+=v[1]
        if current[0]>=0 and current[0]<len(world) and current[1]>=0 and current[1]<len(world[0]):
            if world[current[0]][current[1]]<=-6:
                print("water")
            else:
                climb=max(0,world[current[0]][current[1]]-world[last[0]][last[1]]) #non 0 value of total climb
                energy+=1+climb
                
    print("total energy consumed",energy)
    plt.plot(pathy,pathx)
    #"""


\end{lstlisting}

\bibliographystyle{unsrt}
\bibliography{sample}

\end{document}